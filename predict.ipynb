{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "datapath = 'data/tcd ml 2019-20 income prediction test (without labels).csv'\n",
    "instances = pd.read_csv(datapath).loc[:, 'Instance']\n",
    "# source: https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n",
    "# The top rows were removed to aid in parsing\n",
    "gdp = pd.read_csv('data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_180634.csv', skiprows=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for ml algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def clean_country(country):\n",
    "    try:\n",
    "        return {\n",
    "            'Laos': 'Lao PDR',\n",
    "            'Kyrgyzstan': 'Kyrgyz Republic',\n",
    "            'Slovakia': 'Slovak Republic',\n",
    "            'Congo': 'Congo, Rep.',\n",
    "            'DR Congo': 'Congo, Dem. Rep.',\n",
    "            # Nothing political intended here, trying to be realistic about income\n",
    "            'State of Palestine': 'Jordan',\n",
    "            'Syria': 'Syrian Arab Republic',\n",
    "            'Gambia': 'Gambia, The',\n",
    "            'North Korea': 'Korea, Dem. People’s Rep.',\n",
    "            'South Korea': 'Korea, Rep.',\n",
    "            'Côte d\\'Ivoire': 'Cote d\\'Ivoire',\n",
    "            'Venezuela': 'Venezuela, RB',\n",
    "            'Yemen': 'Yemen, Rep.',\n",
    "            'Brunei': 'Brunei Darussalam',\n",
    "            'Micronesia': 'Micronesia, Fed. Sts.',\n",
    "            'Bahamas': 'Bahamas, The',\n",
    "            'Saint Lucia': 'St. Lucia',\n",
    "            'Czechia': 'Czech Republic',\n",
    "            'Sao Tome & Principe': 'Sao Tome and Principe',\n",
    "        }[country]\n",
    "    except KeyError:\n",
    "        return country\n",
    "\n",
    "def get_index_equiv(year):\n",
    "    return year - 1956\n",
    "\n",
    "def country_to_gdp(countries):\n",
    "    return_val = {}\n",
    "    for country in countries:\n",
    "        try:\n",
    "            gdpval = np.nan\n",
    "            year = 2018\n",
    "            while np.isnan(gdpval):\n",
    "                gdpval = gdp.loc[gdp['Country Name'] == clean_country(country)].iloc[:, get_index_equiv(year)].item()\n",
    "                year -= 1\n",
    "                if year < 1960:\n",
    "                    if country == 'North Korea':\n",
    "                        # There isn't World Bank data for NK, let's assume it's USD32 Billion\n",
    "                        gdpval = float(32000000000)\n",
    "                    else:\n",
    "                        raise IndexError('Could not find GDP')\n",
    "            return_val[country] = gdpval\n",
    "        except ValueError:\n",
    "            print('Country Error, check : clean_country() -> ', country)\n",
    "    return return_val\n",
    "\n",
    "def shorten_jobs(jobs, length=8, thresh=80):\n",
    "    return_val = {}\n",
    "    for key in jobs:\n",
    "        if jobs[key] > thresh:\n",
    "            try:\n",
    "                new_key = key[:length]\n",
    "            except TypeError:\n",
    "                new_key = 'unkn'\n",
    "        else:\n",
    "            new_key = 'unkn'\n",
    "        return_val[key] = new_key\n",
    "    \n",
    "    # Make sure that there aren't any duplicates\n",
    "    for key in return_val:\n",
    "        try:\n",
    "            return_val[return_val[key]]\n",
    "            return_val[key] = 'unkn'\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    return return_val\n",
    "\n",
    "def one_hot_encode(data, column):\n",
    "    degree_encoder = pk.load(open(column.replace(' ', '_') + '.pkl', mode='rb'))\n",
    "    transformed = degree_encoder.transform(data[column])\n",
    "    ohe_df = pd.DataFrame(transformed)\n",
    "    return pd.concat([data, ohe_df], axis=1).drop([column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path, \n",
    "                 Instance_drop, \n",
    "                 Year_of_Record_drop, \n",
    "                 Gender_drop, \n",
    "                 Age_drop, \n",
    "                 Country_drop, \n",
    "                 Size_of_City_drop, \n",
    "                 Profession_drop, \n",
    "                 University_Degree_drop, \n",
    "                 Wears_Glasses_drop, \n",
    "                 Hair_Color_drop, \n",
    "                 Body_Height_cm_drop,\n",
    "                 prof_len=4,\n",
    "                 prof_cutoff=80,\n",
    "):\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.fillna(value=0)\n",
    "\n",
    "    ## 'Instance'\n",
    "    if Instance_drop == True:\n",
    "        data = data.drop(labels='Instance', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Year of Record'\n",
    "    if Year_of_Record_drop == True:\n",
    "        data = data.drop(labels='Year of Record', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Gender'\n",
    "    if Gender_drop == True:\n",
    "        data = data.drop(labels='Gender', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'Gender': {\n",
    "                'male': 1,\n",
    "                'female': -1,\n",
    "                'other': 0,\n",
    "                'unknown': 0,\n",
    "                '0': 0,\n",
    "                np.nan: 0,\n",
    "        }})\n",
    "\n",
    "    ## 'Age'\n",
    "    if Age_drop == True:\n",
    "        data = data.drop(labels='Age', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Country'\n",
    "    # Replace country with its GDP\n",
    "    if Country_drop == True:\n",
    "        data = data.drop(labels='Country', axis=1)\n",
    "    else:\n",
    "        country_gdp = {'Country': country_to_gdp(pd.Series.to_dict(data['Country'].value_counts()))}\n",
    "        data = data.replace(to_replace=country_gdp)\n",
    "\n",
    "    ## 'Size of City'\n",
    "    if Size_of_City_drop == True:\n",
    "        data = data.drop(labels='Size of City', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Profession'\n",
    "    if Profession_drop == True:\n",
    "        data = data.drop(labels='Profession', axis=1)\n",
    "    else:\n",
    "        # shorten labels\n",
    "        new_jobs = pk.load(open('jobs.pkl', mode='rb'))\n",
    "        data = data.replace(to_replace=new_jobs)\n",
    "\n",
    "        # one-hot encode \n",
    "        data = one_hot_encode(data, 'Profession')\n",
    "\n",
    "    ## 'University Degree'\n",
    "    if University_Degree_drop == True:\n",
    "        data = data.drop(labels='University Degree', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'University Degree': {\n",
    "                '0': 'No',\n",
    "                0: 'No',\n",
    "                np.nan: 'No',\n",
    "        }})\n",
    "\n",
    "        data = one_hot_encode(data, 'University Degree')\n",
    "\n",
    "    ## 'Wears Glasses'\n",
    "    if Wears_Glasses_drop == True:\n",
    "        data = data.drop(labels='Wears Glasses', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Hair Color'\n",
    "    if Hair_Color_drop == True:\n",
    "        data = data.drop(labels='Hair Color', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'Hair Color': {\n",
    "                np.nan: 'Unknown',\n",
    "                '0': 'Unknown',\n",
    "                0: 'Unknown',\n",
    "        }})\n",
    "        data = one_hot_encode(data, 'Hair Color')\n",
    "\n",
    "    ## 'Body Height [cm]'\n",
    "    if Body_Height_cm_drop == True:\n",
    "        data = data.drop(labels='Body Height [cm]', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Income in EUR'\n",
    "    # nothing to do here\n",
    "    \n",
    "    return data\n",
    "\n",
    "def scale_data(data):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    scaler = pk.load(open('scaler.pkl', mode='rb'))\n",
    "    X = data.drop(columns=['Income'])#\n",
    "    return scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:41: FutureWarning: `item` has been deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "data = process_data(\n",
    "    datapath, \n",
    "    \n",
    "    Instance_drop           = True,\n",
    "    Year_of_Record_drop     = False,\n",
    "    Gender_drop             = False,\n",
    "    Age_drop                = False,\n",
    "    Country_drop            = False,\n",
    "    Size_of_City_drop       = True,\n",
    "    Profession_drop         = True,\n",
    "    University_Degree_drop  = False,\n",
    "    Wears_Glasses_drop      = False,\n",
    "    Hair_Color_drop         = True,\n",
    "    Body_Height_cm_drop     = False,\n",
    "    \n",
    "    prof_len                = 8,\n",
    "    prof_cutoff             = 80,\n",
    ")\n",
    "X = scale_data(data)\n",
    "\n",
    "\n",
    "func = pk.load(open('predictor.pkl', mode='rb'))\n",
    "\n",
    "ans = func.predict(X)\n",
    "ins = instances.to_numpy()\n",
    "output = []\n",
    "assert(len(ans) == len(ins))\n",
    "\n",
    "for i in range(len(ans)):\n",
    "    output.append([ins[i], ans[i]])\n",
    "# print(output)\n",
    "np.savetxt('output.csv', output, delimiter=',', fmt='%d,%.2f', header='Instance,Income', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression # N/A\n",
    "# from sklearn.tree import DecisionTreeRegressor # 0.5144117272297519\n",
    "# from sklearn.ensemble import RandomForestRegressor # 0.6767255620150188\n",
    "# from sklearn.neighbors import KNeighborsRegressor # -0.15649302917615013\n",
    "# from sklearn.neural_network import MLPRegressor # 0.009245706360739738\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.svm import SVR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pk.dump(func, open('predictor.pkl', mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
