{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "datapath = 'data/tcd ml 2019-20 income prediction test (without labels).csv'\n",
    "instances = pd.read_csv(datapath).loc[:, 'Instance']\n",
    "\n",
    "# # source: https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n",
    "# # The top rows were removed to aid in parsing\n",
    "# gdp = pd.read_csv('data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_180634.csv', skiprows=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See train.ipynb for a better explanation of the code, this mirrors it in large part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some helper functions\n",
    "\n",
    "\n",
    "# def clean_country(country):\n",
    "#     try:\n",
    "#         return {\n",
    "#             'Laos': 'Lao PDR',\n",
    "#             'Kyrgyzstan': 'Kyrgyz Republic',\n",
    "#             'Slovakia': 'Slovak Republic',\n",
    "#             'Congo': 'Congo, Rep.',\n",
    "#             'DR Congo': 'Congo, Dem. Rep.',\n",
    "#             # Nothing political intended here, trying to be realistic about income\n",
    "#             'State of Palestine': 'Jordan',\n",
    "#             'Syria': 'Syrian Arab Republic',\n",
    "#             'Gambia': 'Gambia, The',\n",
    "#             'North Korea': 'Korea, Dem. People’s Rep.',\n",
    "#             'South Korea': 'Korea, Rep.',\n",
    "#             'Côte d\\'Ivoire': 'Cote d\\'Ivoire',\n",
    "#             'Venezuela': 'Venezuela, RB',\n",
    "#             'Yemen': 'Yemen, Rep.',\n",
    "#             'Brunei': 'Brunei Darussalam',\n",
    "#             'Micronesia': 'Micronesia, Fed. Sts.',\n",
    "#             'Bahamas': 'Bahamas, The',\n",
    "#             'Saint Lucia': 'St. Lucia',\n",
    "#             'Czechia': 'Czech Republic',\n",
    "#             'Sao Tome & Principe': 'Sao Tome and Principe',\n",
    "#         }[country]\n",
    "#     except KeyError:\n",
    "#         return country\n",
    "\n",
    "# def get_index_equiv(year):\n",
    "#     return year - 1956\n",
    "\n",
    "# def country_to_gdp(countries):\n",
    "#     return_val = {}\n",
    "#     for country in countries:\n",
    "#         try:\n",
    "#             gdpval = np.nan\n",
    "#             year = 2018\n",
    "#             while np.isnan(gdpval):\n",
    "#                 gdpval = gdp.loc[gdp['Country Name'] == clean_country(country)].iloc[:, get_index_equiv(year)].item()\n",
    "#                 year -= 1\n",
    "#                 if year < 1960:\n",
    "#                     if country == 'North Korea':\n",
    "#                         # There isn't World Bank data for NK, let's assume it's USD32 Billion\n",
    "#                         gdpval = float(32000000000)\n",
    "#                     else:\n",
    "#                         raise IndexError('Could not find GDP')\n",
    "#             return_val[country] = gdpval\n",
    "#         except ValueError:\n",
    "#             print('Country Error, check : clean_country() -> ', country)\n",
    "#     return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def shorten_jobs(jobs, length=8, thresh=80):\n",
    "    return_val = {}\n",
    "    for key in jobs:\n",
    "        if jobs[key] > thresh:\n",
    "            try:\n",
    "                new_key = key[:length]\n",
    "            except TypeError:\n",
    "                new_key = 'unkn'\n",
    "        else:\n",
    "            new_key = 'unkn'\n",
    "        return_val[key] = new_key\n",
    "    \n",
    "    # Make sure that there aren't any duplicates\n",
    "    for key in return_val:\n",
    "        try:\n",
    "            return_val[return_val[key]]\n",
    "            return_val[key] = 'unkn'\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    return return_val\n",
    "\n",
    "def one_hot_encode(data, column):\n",
    "    degree_encoder = LabelBinarizer()\n",
    "    degree_encoder.fit(data[column])\n",
    "    degree_encoder = pk.load(open(column.replace(' ', '_') + '.pkl', mode='rb'))\n",
    "    transformed = degree_encoder.transform(data[column])\n",
    "    ohe_df = pd.DataFrame(transformed)\n",
    "    return pd.concat([data, ohe_df], axis=1).drop([column], axis=1)\n",
    "\n",
    "def fit_to_value(data, column):\n",
    "    return pk.load(open(column + '.pkl', mode='rb'))\n",
    "\n",
    "def trash_strings(data, column):\n",
    "    values = pd.Series.to_dict(data[column])\n",
    "    \n",
    "    fitted = {}\n",
    "    \n",
    "    for i in values:\n",
    "        try:\n",
    "            fitted[str(values[i])] = float(values[i])\n",
    "        except ValueError:\n",
    "            fitted[values[i]] = 106100.63\n",
    "            \n",
    "    return fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path, \n",
    "                 Instance_drop, \n",
    "                 Year_of_Record_drop, \n",
    "                 Gender_drop, \n",
    "                 Age_drop, \n",
    "                 Country_drop, \n",
    "                 Size_of_City_drop, \n",
    "                 Profession_drop, \n",
    "                 University_Degree_drop, \n",
    "                 Wears_Glasses_drop, \n",
    "                 Hair_Color_drop, \n",
    "                 Body_Height_cm_drop,\n",
    "                 prof_len=4,\n",
    "                 prof_cutoff=80,\n",
    "                 replace_gdp = True,\n",
    "                 replace_est_gdp = False,\n",
    "                 scale_uni = True,\n",
    "                 drop_income_outlier = True,\n",
    "                 income_cutoff = 1000000,\n",
    "                 gdp_cutoff = 1.5*pow(10,12),\n",
    "):\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.fillna(value=0)\n",
    "\n",
    "    ## 'Instance'\n",
    "    print(' * INFO: Processing \\'Instance\\'')\n",
    "    if Instance_drop == True:\n",
    "        data = data.drop(labels='Instance', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Year of Record'\n",
    "    print(' * INFO: Processing \\'Year of Record\\'')\n",
    "    if Year_of_Record_drop == True:\n",
    "        data = data.drop(labels='Year of Record', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'Year of Record': {\n",
    "                0: 2000,\n",
    "        }})\n",
    "\n",
    "    ## 'Gender'\n",
    "    print(' * INFO: Processing \\'Gender\\'')\n",
    "    if Gender_drop == True:\n",
    "        data = data.drop(labels='Gender', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'Gender': {\n",
    "                'male': 1,\n",
    "                'female': -1,\n",
    "                'other': 0,\n",
    "                'unknown': 0,\n",
    "                '0': 0,\n",
    "                np.nan: 0,\n",
    "        }})\n",
    "\n",
    "    ## 'Age'\n",
    "    print(' * INFO: Processing \\'Age\\'')\n",
    "    if Age_drop == True:\n",
    "        data = data.drop(labels='Age', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'Age': {\n",
    "                0: 40,\n",
    "        }})\n",
    "\n",
    "    ## 'Country'\n",
    "    print(' * INFO: Processing \\'Country\\'')\n",
    "    assert((replace_gdp != replace_est_gdp) or ((replace_gdp == False) and (replace_est_gdp == False)))\n",
    "    # Replace country with its GDP\n",
    "    if Country_drop == True:\n",
    "        data = data.drop(labels='Country', axis=1)\n",
    "    else:\n",
    "        if replace_gdp == True:\n",
    "            country_gdp = {'Country': country_to_gdp(pd.Series.to_dict(data['Country'].value_counts()))}\n",
    "            data = data.replace(to_replace=country_gdp)\n",
    "        elif replace_est_gdp == True:\n",
    "\n",
    "            country_gdp = {'Country': fit_to_value(data, 'Country')}\n",
    "            data = data.replace(to_replace=country_gdp)\n",
    "            # Some countries in the unlabelled dataset are not found in\n",
    "            # the labelled dataset, this is a terrible quick fix for this\n",
    "            # 486262.74 is the average income overall\n",
    "            data = data.replace(to_replace={'Country': {\n",
    "                'Iceland': 486262.74,\n",
    "                'Italy': 486262.74,\n",
    "                'Turkey': 486262.74,\n",
    "                'Samoa': 486262.74,\n",
    "                'Sao Tome & Principe': 486262.74,\n",
    "                'France': 486262.74,\n",
    "            }})\n",
    "        else:\n",
    "            data = one_hot_encode(data, 'Country')\n",
    "\n",
    "    ## 'Size of City'\n",
    "    print(' * INFO: Processing \\'Size of City\\'')\n",
    "    if Size_of_City_drop == True:\n",
    "        data = data.drop(labels='Size of City', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Profession'\n",
    "    print(' * INFO: Processing \\'Profession\\'')\n",
    "    if Profession_drop == True:\n",
    "        data = data.drop(labels='Profession', axis=1)\n",
    "    else:\n",
    "        # shorten labels\n",
    "        new_jobs = {'Profession': \n",
    "                    shorten_jobs(\n",
    "                        pd.Series.to_dict(data['Profession'].value_counts()), \n",
    "                        prof_len,\n",
    "                        prof_cutoff\n",
    "                    )}\n",
    "        new_jobs = pk.load(open('jobs.pkl', mode='rb'))\n",
    "        data = data.replace(to_replace=new_jobs)\n",
    "        \n",
    "        newjobs = {'Profession': fit_to_value(data, 'Profession')}\n",
    "        data = data.replace(to_replace=newjobs)\n",
    "        \n",
    "        data = data.replace(to_replace={'Profession': trash_strings(data, 'Profession')})\n",
    "\n",
    "#         # one-hot encode \n",
    "#         data = one_hot_encode(data, 'Profession')\n",
    "\n",
    "    ## 'University Degree'\n",
    "    print(' * INFO: Processing \\'University Degree\\'')\n",
    "    if University_Degree_drop == True:\n",
    "        data = data.drop(labels='University Degree', axis=1)\n",
    "    else:\n",
    "        if scale_uni == True:\n",
    "            data = data.replace(to_replace={'University Degree': {\n",
    "                    'PhD': 3,\n",
    "                    'Master': 2,\n",
    "                    'Bachelor': 1,\n",
    "                    '0': 0,\n",
    "                    'No': 0,\n",
    "                    np.nan: 0,\n",
    "            }})\n",
    "            data['University Degree'] = pd.to_numeric(data['University Degree'], downcast='float')\n",
    "        else:\n",
    "            data = data.replace(to_replace={'University Degree': {\n",
    "                    '0': 'No',\n",
    "                    0: 'No',\n",
    "                    np.nan: 'No',\n",
    "            }})\n",
    "\n",
    "            data = one_hot_encode(data, 'University Degree')\n",
    "\n",
    "    ## 'Wears Glasses'\n",
    "    print(' * INFO: Processing \\'Wears Glasses\\'')\n",
    "    if Wears_Glasses_drop == True:\n",
    "        data = data.drop(labels='Wears Glasses', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Hair Color'\n",
    "    print(' * INFO: Processing \\'Hair Color\\'')\n",
    "    if Hair_Color_drop == True:\n",
    "        data = data.drop(labels='Hair Color', axis=1)\n",
    "    else:\n",
    "        data = data.replace(to_replace={'Hair Color': {\n",
    "                np.nan: 'Unknown',\n",
    "                '0': 'Unknown',\n",
    "                0: 'Unknown',\n",
    "        }})\n",
    "        data = one_hot_encode(data, 'Hair Color')\n",
    "\n",
    "    ## 'Body Height [cm]'\n",
    "    print(' * INFO: Processing \\'Body Height [cm]\\'')\n",
    "    if Body_Height_cm_drop == True:\n",
    "        data = data.drop(labels='Body Height [cm]', axis=1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    ## 'Income in EUR'\n",
    "    print(' * INFO: Processing \\'Income in EUR\\'')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def split_scale_data(data):\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    scaler = pk.load(open('scaler.pkl', mode='rb'))\n",
    "    X = data.drop(columns=['Income'])#\n",
    "    return scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * INFO: Processing data\n",
      " * INFO: Processing 'Instance'\n",
      " * INFO: Processing 'Year of Record'\n",
      " * INFO: Processing 'Gender'\n",
      " * INFO: Processing 'Age'\n",
      " * INFO: Processing 'Country'\n",
      " * INFO: Processing 'Size of City'\n",
      " * INFO: Processing 'Profession'\n",
      " * INFO: Processing 'University Degree'\n",
      " * INFO: Processing 'Wears Glasses'\n",
      " * INFO: Processing 'Hair Color'\n",
      " * INFO: Processing 'Body Height [cm]'\n",
      " * INFO: Processing 'Income in EUR'\n",
      " * INFO: Data processed, predicting\n"
     ]
    }
   ],
   "source": [
    "print(' * INFO: Processing data')\n",
    "data = process_data(\n",
    "    datapath, \n",
    "    \n",
    "    Instance_drop           = True,\n",
    "    Year_of_Record_drop     = False,\n",
    "    Gender_drop             = True,\n",
    "    Age_drop                = False,\n",
    "    Country_drop            = False,\n",
    "    Size_of_City_drop       = True,\n",
    "    Profession_drop         = False,\n",
    "    University_Degree_drop  = False, # don't drop\n",
    "    Wears_Glasses_drop      = False, # don't drop\n",
    "    Hair_Color_drop         = True, # don't drop\n",
    "    Body_Height_cm_drop     = False, # don't drop\n",
    "    \n",
    "    prof_len                = 2,\n",
    "    prof_cutoff             = 1,\n",
    "    \n",
    "    replace_gdp             = False,\n",
    "    replace_est_gdp         = True,\n",
    "    scale_uni               = True,\n",
    "    drop_income_outlier     = True,\n",
    "    gdp_cutoff              = 1.5*pow(10,12),\n",
    ")\n",
    "\n",
    "X = split_scale_data(data)\n",
    "\n",
    "print(' * INFO: Data processed, predicting')\n",
    "\n",
    "func = pk.load(open('predictor.pkl', mode='rb'))\n",
    "ans = func.predict(X)\n",
    "ins = instances.to_numpy()\n",
    "output = []\n",
    "assert(len(ans) == len(ins))\n",
    "\n",
    "for i in range(len(ans)):\n",
    "    output.append([ins[i], ans[i]])\n",
    "# print(output)\n",
    "np.savetxt('output.csv', output, delimiter=',', fmt='%d,%.2f', header='Instance,Income', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
