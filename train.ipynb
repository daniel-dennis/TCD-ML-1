{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "data = pd.read_csv('data/tcd ml 2019-20 income prediction training (with labels).csv')\n",
    "\n",
    "# source: https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n",
    "# The top rows were removed to aid in parsing\n",
    "gdp = pd.read_csv('data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_180634.csv', skiprows=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for ml algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_country(country):\n",
    "    try:\n",
    "        return {\n",
    "            'Laos': 'Lao PDR',\n",
    "            'Kyrgyzstan': 'Kyrgyz Republic',\n",
    "            'Slovakia': 'Slovak Republic',\n",
    "            'Congo': 'Congo, Rep.',\n",
    "            'DR Congo': 'Congo, Dem. Rep.',\n",
    "            # Nothing political intended here, trying to be realistic about income\n",
    "            'State of Palestine': 'Jordan',\n",
    "            'Syria': 'Syrian Arab Republic',\n",
    "            'Gambia': 'Gambia, The',\n",
    "            'North Korea': 'Korea, Dem. People’s Rep.',\n",
    "            'South Korea': 'Korea, Rep.',\n",
    "            'Côte d\\'Ivoire': 'Cote d\\'Ivoire',\n",
    "            'Venezuela': 'Venezuela, RB',\n",
    "            'Yemen': 'Yemen, Rep.',\n",
    "            'Brunei': 'Brunei Darussalam',\n",
    "            'Micronesia': 'Micronesia, Fed. Sts.',\n",
    "            'Bahamas': 'Bahamas, The',\n",
    "            'Saint Lucia': 'St. Lucia',\n",
    "            'Czechia': 'Czech Republic',\n",
    "            'Sao Tome & Principe': 'Sao Tome and Principe',\n",
    "        }[country]\n",
    "    except KeyError:\n",
    "        return country\n",
    "\n",
    "def get_index_equiv(year):\n",
    "    return year - 1956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n",
      "/usr/local/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:35: FutureWarning: `item` has been deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "data = pd.read_csv('data/tcd ml 2019-20 income prediction training (with labels).csv')\n",
    "data = data.fillna(value=0)\n",
    "\n",
    "## 'Instance'\n",
    "data = data.drop(labels='Instance', axis=1)\n",
    "\n",
    "## 'Year of Record'\n",
    "# nothing to do here\n",
    "\n",
    "## 'Gender'\n",
    "data = data.replace(to_replace={'Gender': {\n",
    "        'male': 1,\n",
    "        'female': -1,\n",
    "        'other': 0,\n",
    "        'unknown': 0,\n",
    "        '0': 0,\n",
    "        np.nan: 0,\n",
    "}})\n",
    "\n",
    "## 'Age'\n",
    "# nothing to do here\n",
    "\n",
    "## 'Country'\n",
    "# Replace country with its GDP\n",
    "countries = pd.Series.to_dict(data['Country'].value_counts())\n",
    "country_gdp = {'Country': {}}\n",
    "\n",
    "for country in countries:\n",
    "    try:\n",
    "        gdpval = np.nan\n",
    "        year = 2018\n",
    "        while np.isnan(gdpval):\n",
    "            gdpval = gdp.loc[gdp['Country Name'] == clean_country(country)].iloc[:, get_index_equiv(year)].item()\n",
    "            year -= 1\n",
    "            if year < 1960:\n",
    "                if country == 'North Korea':\n",
    "                    gdpval = float(32000000000) # There isn't World Bank for NK, assume it's USD32 Billion\n",
    "                else:\n",
    "                    raise IndexError('Could not find GDP')\n",
    "        country_gdp['Country'][country] = gdpval\n",
    "    except ValueError:\n",
    "        print('Country Error, check : clean_country() -> ', country)\n",
    "\n",
    "data = data.replace(to_replace=country_gdp)\n",
    "\n",
    "## 'Size of City'\n",
    "# nothing to do here\n",
    "\n",
    "## 'Profession'\n",
    "# shorten labels\n",
    "jobs = pd.Series.to_dict(data['Profession'].value_counts())\n",
    "new_jobs = {'Profession': {}}\n",
    "\n",
    "for key in jobs:\n",
    "    if jobs[key] > 80:\n",
    "        try:\n",
    "            new_key = key[:4]\n",
    "        except TypeError:\n",
    "            new_key = 'unkn'\n",
    "    else:\n",
    "        new_key = 'unkn'\n",
    "    new_jobs['Profession'][key] = new_key\n",
    "    \n",
    "for key in new_jobs['Profession']:\n",
    "    try:\n",
    "        temp = new_jobs['Profession'][new_jobs['Profession'][key]]\n",
    "        new_jobs['Profession'][key] = 'unkn'\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "pk.dump(new_jobs, open('jobs.pkl', mode='wb'))\n",
    "data = data.replace(to_replace=new_jobs)\n",
    "\n",
    "# one-hot encode \n",
    "\n",
    "jobs_encoder = LabelBinarizer()\n",
    "jobs_encoder.fit(data['Profession'])\n",
    "pk.dump(jobs_encoder, open('jobs_encoder.pkl', mode='wb'))\n",
    "\n",
    "transformed = jobs_encoder.transform(data['Profession'])\n",
    "ohe_df = pd.DataFrame(transformed)\n",
    "data = pd.concat([data, ohe_df], axis=1).drop(['Profession'], axis=1)\n",
    "\n",
    "## 'University Degree'\n",
    "data = data.replace(to_replace={'University Degree': {\n",
    "        '0': 'No',\n",
    "        0: 'No',\n",
    "}})\n",
    "\n",
    "degree_encoder = LabelBinarizer()\n",
    "degree_encoder.fit(data['University Degree'])\n",
    "pk.dump(degree_encoder, open('degree_encoder.pkl', mode='wb'))\n",
    "\n",
    "transformed = degree_encoder.transform(data['University Degree'])\n",
    "ohe_df = pd.DataFrame(transformed)\n",
    "data = pd.concat([data, ohe_df], axis=1).drop(['University Degree'], axis=1)\n",
    "\n",
    "## 'Wears Glasses'\n",
    "data = data.drop(labels='Wears Glasses', axis=1)\n",
    "\n",
    "## 'Hair Color'\n",
    "data = data.drop(labels='Hair Color', axis=1)\n",
    "\n",
    "## 'Body Height [cm]'\n",
    "## 'Income in EUR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = data.corr()\n",
    "# corr_matrix['Country']\n",
    "# data.head()\n",
    "# print(country_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Income in EUR'])#.to_numpy()\n",
    "y = data.loc[:, 'Income in EUR']#.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "pk.dump(scaler, open('scaler.pkl', mode='wb'))\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6907547769724358"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # N/A\n",
    "from sklearn.tree import DecisionTreeRegressor # 0.5144117272297519\n",
    "from sklearn.ensemble import RandomForestRegressor # 0.6767255620150188\n",
    "from sklearn.neighbors import KNeighborsRegressor # -0.15649302917615013\n",
    "from sklearn.neural_network import MLPRegressor # 0.009245706360739738\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "func = RandomForestRegressor(\n",
    "    n_estimators=50, \n",
    "    n_jobs=-1,\n",
    "    random_state=2645, # for consistency between runs\n",
    "    verbose=1\n",
    ")\n",
    "func.fit(X_train, y_train)\n",
    "func.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(func, open('predictor.pkl', mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pk.dump(func, open('predictor.pkl', mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
